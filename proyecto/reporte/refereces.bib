@misc{girshick2013rich,
    title={Rich feature hierarchies for accurate object detection and semantic segmentation},
    author={Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
    year={2013},
    eprint={1311.2524},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{zhao2018object,
	title={Object Detection with Deep Learning: A Review},
	author={Zhong-Qiu Zhao and Peng Zheng and Shou-tao Xu and Xindong Wu},
	year={2018},
	eprint={1807.05511},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@INPROCEEDINGS{girshick,
	
	author={R. {Girshick} and J. {Donahue} and T. {Darrell} and J. {Malik}},
	
	booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
	
	title={Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation}, 
	
	year={2014},
	
	volume={},
	
	number={},
	
	pages={580-587},
}

@misc{redmon2015look,
	title={You Only Look Once: Unified, Real-Time Object Detection},
	author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
	year={2015},
	eprint={1506.02640},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{howard2017mobilenets,
	title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
	author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
	year={2017},
	eprint={1704.04861},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@InProceedings{alcantarilla,
	author="Alcantarilla, Pablo Fern{\'a}ndez
	and Bartoli, Adrien
	and Davison, Andrew J.",
	editor="Fitzgibbon, Andrew
	and Lazebnik, Svetlana
	and Perona, Pietro
	and Sato, Yoichi
	and Schmid, Cordelia",
	title="KAZE Features",
	booktitle="Computer Vision -- ECCV 2012",
	year="2012",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="214--227",
	abstract="In this paper, we introduce KAZE features, a novel multiscale 2D feature detection and description algorithm in nonlinear scale spaces. Previous approaches detect and describe features at different scale levels by building or approximating the Gaussian scale space of an image. However, Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same degree both details and noise, reducing localization accuracy and distinctiveness. In contrast, we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering. In this way, we can make blurring locally adaptive to the image data, reducing noise but retaining object boundaries, obtaining superior localization accuracy and distinctiviness. The nonlinear scale space is built using efficient Additive Operator Splitting (AOS) techniques and variable conductance diffusion. We present an extensive evaluation on benchmark datasets and a practical matching application on deformable surfaces. Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space, but comparable to SIFT, our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods.",
	isbn="978-3-642-33783-3"
}

@article{doi:10.1162/neco\_a\_00990,
	author = {Rawat, Waseem and Wang, Zenghui},
	title = {Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review},
	journal = {Neural Computation},
	volume = {29},
	number = {9},
	pages = {2352-2449},
	year = {2017},
	doi = {10.1162/neco\_a\_00990},
	note ={PMID: 28599112},
	
	URL = { 
	https://doi.org/10.1162/neco_a_00990
	
	},
	eprint = { 
	https://doi.org/10.1162/neco_a_00990
	
	}
	,
	abstract = { Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s. However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems. Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have contributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications. We also introduce some of their current trends and remaining challenges. }
}

@misc{yosinski2014transferable,
	title={How transferable are features in deep neural networks?},
	author={Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
	year={2014},
	eprint={1411.1792},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

